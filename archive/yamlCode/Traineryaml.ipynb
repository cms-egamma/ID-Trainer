{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "independent-cabin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/00\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import uproot\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ROOT\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "os.system(\"\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "monetary-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools.PlotTools import *\n",
    "\n",
    "TrainConfig='Config.yaml'\n",
    "\n",
    "with open(r''+TrainConfig+'') as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    Conf = yaml.load(file,Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surrounded-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Running in debug mode : Only every 10th event will be used\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "if Conf['Debug']==True:\n",
    "    prGreen(\"Running in debug mode : Only every 10th event will be used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alive-excuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Making output directory\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(Conf['MVAs'])>0:\n",
    "    for key in Conf['MVAs']:\n",
    "        os.system(\"mkdir -p \" + Conf['OutputDirName']+\"/\"+str(key))\n",
    "prGreen(\"Making output directory\")\n",
    "os.system(\"mkdir -p \" + Conf['OutputDirName'])\n",
    "os.system(\"mkdir -p \" + Conf['OutputDirName']+\"/CodeANDConfig\")\n",
    "os.system(\"mkdir -p \" + Conf['OutputDirName']+\"/Thresholds\")\n",
    "os.system(\"cp \"+TrainConfig+\" ./\"+ Conf['OutputDirName']+\"/CodeANDConfig/\")\n",
    "os.system(\"cp Config.yaml ./\"+ Conf['OutputDirName']+\"/CodeANDConfig/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incorporate-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m You have chosen these MVAs\u001b[00m\n",
      "['XGB_1', 'XGB_2', 'DNN_1']\n",
      "\u001b[92m You have these classes\u001b[00m\n",
      "['DYJets', 'bcTOEQCD', 'GJet']\n"
     ]
    }
   ],
   "source": [
    "prGreen(\"You have chosen these MVAs\")\n",
    "print(list(Conf['MVAs'].keys()))\n",
    "prGreen(\"You have these classes\")\n",
    "print(list(Conf['ClassKinds'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "talented-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat='EleType'\n",
    "weight=\"NewWt\"\n",
    "labels=list(Conf['ClassKinds'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "academic-preparation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version:  2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print('Using Keras version: ', tf.keras.__version__)\n",
    "\n",
    "do_model_fit = 1\n",
    "number_of_classes = len(list(Conf['ClassKinds'].keys()))\n",
    "# Create instance of output directory where all results are saved.\n",
    "output_directory = Conf['OutputDirName']\n",
    "od = output_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-payroll",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "genetic-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (105) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "if not Conf['LoadSavedDataFrame']:\n",
    "    df=pd.DataFrame()\n",
    "    for i,ClassKind in enumerate(list(Conf['ClassKinds'].keys())):\n",
    "        FileLocations=list(Conf['ClassKinds'][ClassKind]['FileLocations'])\n",
    "        Trees=list(Conf['ClassKinds'][ClassKind]['Trees'])\n",
    "        Cuts=list(Conf['ClassKinds'][ClassKind]['Cuts'])\n",
    "        Wts=list(Conf['ClassKinds'][ClassKind]['Wts'])\n",
    "        for Loc,Tree,Cut,Wt in zip(FileLocations,Trees,Cuts,Wts):\n",
    "            if Conf['Debug']==True:\n",
    "                dfi=pd.DataFrame()\n",
    "                print(ClassKind)\n",
    "                print(Loc)\n",
    "                print(Tree)\n",
    "                print(Cut)\n",
    "                if Conf['Splitting']['CriteriaBased']:\n",
    "                    #prGreen(\"CriteriaBased Splitting and Debug is True\")\n",
    "                    dftri=uproot.open(Loc).get(Tree).pandas.df().query(str(Cut)+' & '+str(Conf['CommonCut'])+' & '+str(Conf['Splitting']['Train_selection_criteria'])).iloc[::10]\n",
    "                    dftri['Dataset']='Train'\n",
    "                    dftri['TrainDataset']=1\n",
    "                    dftei=uproot.open(Loc).get(Tree).pandas.df().query(str(Cut)+' & '+str(Conf['CommonCut'])+' & '+str(Conf['Splitting']['Test_selection_criteria'])).iloc[::10]\n",
    "                    dftei['Dataset']='Test'\n",
    "                    dftei['TrainDataset']=0\n",
    "                    dfi = pd.concat([dftri,dftei],ignore_index=True, sort=False)\n",
    "                else:\n",
    "                    #prGreen(\"Size based Splitting and Debug is True\")\n",
    "                    dfi = uproot.open(Loc).get(Tree).pandas.df().query(str(Cut)+' & '+str(Conf['CommonCut'])).iloc[::10]\n",
    "                    print(len(dfi.index.values.tolist()))\n",
    "                    from sklearn.model_selection import train_test_split\n",
    "                    TrainIndices, TestIndices = train_test_split(dfi.index.values.tolist(), test_size=Conf['Splitting']['testsize'], random_state=Conf['RandomState'], shuffle=True)\n",
    "                    dfi.loc[TrainIndices,'Dataset'] = \"Train\"\n",
    "                    dfi.loc[TestIndices,'Dataset'] = \"Test\"\n",
    "                    dfi.loc[TrainIndices,'TrainDataset'] = 1\n",
    "                    dfi.loc[TestIndices,'TrainDataset'] = 0\n",
    "            else:\n",
    "                if Conf['Splitting']['CriteriaBased']:\n",
    "                    #prGreen(\"CriteriaBased Splitting and Debug is False\")\n",
    "                    dftri=uproot.open(Loc).get(Tree).pandas.df().query(str(Cut)+' & '+str(Conf['CommonCut'])+' & '+str(Conf['Splitting']['Train_selection_criteria']))\n",
    "                    dftri['Dataset']='Train'\n",
    "                    dftri['TrainDataset']=1\n",
    "                    dftei=uproot.open(Loc).get(Tree).pandas.df().query(str(Cut)+' & '+str(Conf['CommonCut'])+' & '+str(Conf['Splitting']['Test_selection_criteria']))\n",
    "                    dftei['Dataset']='Test'\n",
    "                    dftei['TrainDataset']=0\n",
    "                    dfi = pd.concat([dftri,dftei],ignore_index=True, sort=False)                \n",
    "                else:\n",
    "                    #prGreen(\"Size based Splitting and Debug is False\")\n",
    "                    dfi = uproot.open(Loc).get(Tree).pandas.df().query(str(Cut)+' & '+str(Conf['CommonCut']))\n",
    "                    print(len(dfi.index.values.tolist()))\n",
    "                    from sklearn.model_selection import train_test_split\n",
    "                    TrainIndices, TestIndices = train_test_split(dfi.index.values.tolist(), test_size=Conf['Splitting']['testsize'], random_state=Conf['RandomState'], shuffle=True)\n",
    "                    dfi.loc[TrainIndices,'Dataset'] = \"Train\"\n",
    "                    dfi.loc[TestIndices,'Dataset'] = \"Test\"\n",
    "                    dfi.loc[TrainIndices,'TrainDataset'] = 1\n",
    "                    dfi.loc[TestIndices,'TrainDataset'] = 0\n",
    "            dfi['xsecwt']=Wt\n",
    "            dfi[cat]=i\n",
    "            df=pd.concat([df,dfi],ignore_index=True, sort=False)\n",
    "            if Conf['SaveDataFrame']:\n",
    "                df.to_csv('./'+ Conf['OutputDirName'] + '/dfout.zip', index=False,compression='infer')\n",
    "\n",
    "else:\n",
    "    df = pd.read_csv('./'+ Conf['OutputDirName'] + '/dfout.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surprising-clothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Size of training dataset = 85982 events/objects\u001b[00m\n",
      "\u001b[92m Size of testing dataset = 21498 events/objects\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "TrainIndices=df.index[df['TrainDataset'] == 1].tolist()\n",
    "prGreen(\"Size of training dataset = \"+str(len(TrainIndices))+\" events/objects\")\n",
    "TestIndices=df.index[df['TrainDataset'] == 0].tolist()\n",
    "prGreen(\"Size of testing dataset = \"+str(len(TestIndices))+\" events/objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exciting-morrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB_1\n",
      "XGB_2\n"
     ]
    }
   ],
   "source": [
    "for MVA in list(Conf['MVAs'].keys()):\n",
    "    if 'XGB' in MVA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-engagement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-prison",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
